---
title: "Hands on with Harvesting Tweets with R (academictwitteR)"
author: "Sighvatur Sveinn Davidsson"
format: html
editor: visual
---

-   Disposition (for dette ark):

    -   Hvordan fungerer processen?

    -   

## 0.1 Before we get started

\[...\]

```{r}
# Execute this command to see the offical authentication guide 
vignette("academictwitteR-auth")
```

1.  **Acquire a an account that allows you to access the Twitter API \[...\]**

1.  **Store your credentials on your local computer**

When you have acquired the token you have to set your credentials, so that Twitter knows, that it's actually someone, who has permission, that's making the call.

Before we do anything, let's load our package:

```{r}
    
```

To do this we will be configuring our process:

```{r}
# This package loads functions necessary for communicating with the Twitter API
library(academictwitteR) 

# We can now access the following function, that helps us to set the bearer token.
set_bearer()
```

This function opens up a user configuration file called *.Renviron*. In this file we store our credentials in a manner like this:

```{bash}
TWITTER_BEARER=AAAAAAAAAAAAAAAAAAAAAPxAggEAAAAA07AUylWiirV1P7y4$E6P*%KkrWdNAzuM4Sah6N9wF5y^5JoTY2&%CA%9dikVUDJiwPE4ATSBgQZojlYn
```

When you have done this, save the file and restart your r-session. In the menu bar find: **Session -\> Restart R**

Now RStudio should be loaded with your personal token, and you should be ready to start collecting tweets.

**Tips**:

-   The token should be posted on the same line as the variable being defined ("TWITTER_BEARER") and there should be no spaces.

-   If you want to read more about the `set_bearer()` function (or any other function), put a question mark in front of it and read the documentation for it. Like so `?set_bearer()`

-   For experienced R users: Note that the `set_bearer()` takes no input, but behaves in the same way as `usethis::edit_r_environ()`. It simply opens the file, for you to manually paste the token.

### Let's get to it

Remember to load the library before you can access function. This only has to be done once for each session.

The basic syntax looks like this

```{r}
aalborg_tweets <- get_all_tweets(
  query = "aalborg",
  start_tweets = "2020-01-01T00:00:00Z",
  end_tweets = "2020-12-31T23:59:59Z"
)
```

Here's how to read the code:

-   We call the function `get_all_tweets()` and we assign the output of it to the object to the left of it `aalborg_tweets()`.

    -   Assigning the output of a function to an object means, that you can access it later. If you try typing the object name in the console, you will print the contents. If you look in the environment pane, you can access it's contents by clicking on it.

-   The function has three mandatory input arguments, that need to be communicated on to the API:

    -   `query`: This is your actual search term.

    -   `start_tweets`: the starting date and time of your search.

    -   `end_tweets`: the ending date and time of your search.

        -   Some add**itional remarks about the timestamp format in section \[...\]**

**Extra**:

-   When you call the function a call is sent to the Twitter API, with the input parameters you provided. This returns a JSON-file that is converted into a tabular format, that is more R-friendly.

-   Sometimes the output isn't so user friendly: `aalborg_tweets$public_metrics` is a dataframe inside a dataframe

### The output

```{r}
# Load the tidyverse package bundle. 
library(tidyverse)

# Use the glimpse function to look at the variables
glimpse(aalborg_tweets)
```

Here's a quick tour of the output variables. The official documentation can be found [here](https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet). Not only does it describe the variables included - there are also suggestions for analytical uses.

-   **created_at**: the time the tweet was posted.

-   **in_reply_to_user_id**: if the represented tweet is a reply, this will be the id of the user being replied to.

-   **text**: the actual text

-   **public_metric**: a dataframe within the dataframe; holds metrics *retweet_count, reply_count, like_count, quote_count.* This is useful for measuring tweet engagement.

-   **edit_history_tweets_ids**:

-   **id**: the unique identifier of this tweet

-   **author_id**: the unique identifier of the tweet's author

-   **conversation_id**: if the tweet is a part of a conversation, this will be the id of the original tweet.

-   **lang**: language registered by twitter bots. Returned in a BCP47 format.

-   **entitites**:

-   **possibly_sensitive**: marked either by user or twitter agent as containing sensitive information.

-   **referenced_tweets**: a list of tweets being referenced (if tweet is reply or retweet

-   **source**: what application the tweet is generated from.

-   **attachements**:

-   **geo**: geographic location information. **\[see note ...\]**

### Some quick analysis:

```{r}
# What do we have to work with?
glimpse(aalborg_tweets)

# Let's count the languages
lang_tweets <- aalborg_tweets %>% count(lang, sort = TRUE)

# Let's plot the language count
ggplot(lang_tweets) + geom_col(aes(x = lang, y = n))

```

```{r}
# Let's find the most popular tweet
# This one is inside a nested dataframe in the public_metrics. We'll unnest that first.
aalborg_tweets %>% 
  unnest(public_metrics) %>% 
  glimpse()

# Notice the difference from before
glimpse(aalborg_tweets)

# Let's pick out the ones
selected_tweets <- 
aalborg_tweets %>% 
  unnest(public_metrics) %>% 
  select(text, retweet_count, reply_count, like_count, quote_count)

# Let's look at what we have
selected_tweets 

# Gather the numeric values & sort by most popular
most_popular_tweets <-
selected_tweets %>% 
  rowwise() %>% 
  transmute(text, popularity = sum(retweet_count, reply_count, like_count, quote_count)) %>% 
  arrange(-popularity)

most_popular_tweets
```

# We want more!

```{r}
aalborg_tweets <- get_all_tweets(
  query = "aalborg",
  start_tweets = "2020-01-01T00:00:00Z",
  end_tweets = "2020-12-31T23:59:59Z"
)
```

### Extending the function

```{r}
?build_query()
```

Geotags:

*Prevalence:* \~1-2% of Tweets are geo-tagged \[[Source](https://developer.twitter.com/en/docs/tutorials/advanced-filtering-for-geo-data)\]

*Prevalence:* \~30-40% of Tweets contain some profile location information. \[[Source](https://developer.twitter.com/en/docs/tutorials/advanced-filtering-for-geo-data)\]

**Helpers**

```{r}
# Dates are formatted as strings (not datetime-format). Don't confuse that.
# Date conversion


# Expanding the public_metrics

```
